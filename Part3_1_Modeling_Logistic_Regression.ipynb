{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.31 Modeling: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LogisticRegression related pacakges\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lemmatize and Tokenize rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regularexpression to do lemmatize\n",
    "# use countvectorizer to tokenize, lemmatize, and exclude stopwords\n",
    "# cvec = CountVectorizer(tokenizer=LemmaTokenizer()) \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokenizer = RegexpTokenizer('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "        return [self.wnl.lemmatize(t) for t in tokenizer.tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline\n",
    "pipeline_cv = Pipeline([('cvec', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "                        ('lr', LogisticRegression('l1')) \n",
    "                       ])\n",
    "# Pipeline parameter CountVectorizer\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [300, 500, 1000],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed:   11.7s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "gs_cv = GridSearchCV(pipeline_cv, \n",
    "                     param_grid=pipe_params, \n",
    "                     cv=5,\n",
    "                     verbose=1,\n",
    "                     n_jobs=4)\n",
    "\n",
    "lr_cv = gs_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters on the training data:\n",
    "lr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.9606512890094979\n",
      "cross validation score is 0.9185888738127544\n",
      "test score is 0.9247967479674797\n"
     ]
    }
   ],
   "source": [
    "# assign the best estimator to a variable:\n",
    "best_lr_cv = lr_cv.best_estimator_\n",
    "# check training score, cross_validation_score and testing score\n",
    "print(f\"training score is {best_lr_cv.score(X_train, y_train)}\")\n",
    "print(f\"cross validation score is {lr_cv.best_score_}\")\n",
    "print(f\"test score is {best_lr_cv.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Pipeline\n",
    "pipeline_tfidf = Pipeline([('tfidf', TfidfVectorizer(tokenizer=LemmaTokenizer())),\n",
    "                        ('lr', LogisticRegression('l1')) \n",
    "                       ])\n",
    "# Pipeline parameter CountVectorizer\n",
    "pipe_params = {\n",
    "    'tfidf__max_features': [300, 500, 1000],\n",
    "    'tfidf__min_df': [2, 3],\n",
    "    'tfidf__max_df': [.9, .95],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__stop_words': [None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed:    9.8s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "gs_tfidf = GridSearchCV(pipeline_tfidf, \n",
    "                     param_grid=pipe_params, \n",
    "                     cv=5,\n",
    "                     verbose=1,\n",
    "                     n_jobs=4)\n",
    "\n",
    "lr_tfidf = gs_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.9,\n",
       " 'tfidf__max_features': 300,\n",
       " 'tfidf__min_df': 3,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters on the training data:\n",
    "lr_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.9443690637720489\n",
      "cross validation score is 0.9145183175033921\n",
      "test score is 0.9024390243902439\n"
     ]
    }
   ],
   "source": [
    "# assign the best estimator to a variable:\n",
    "best_lr_tfidf = lr_tfidf.best_estimator_\n",
    "# check training score, cross_validation_score and testing score\n",
    "print(f\"training score is {best_lr_tfidf.score(X_train, y_train)}\")\n",
    "print(f\"cross validation score is {lr_tfidf.best_score_}\")\n",
    "print(f\"test score is {best_lr_tfidf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check coefficient to see which feature weights more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since model under CountVectorizer(cv) performs better, I'll use cv to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the best estimator in gridsearch\n",
    "cvec = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                       max_df=0.9,\n",
    "                       max_features=1000,\n",
    "                       min_df=2,\n",
    "                       ngram_range=(1, 2),\n",
    "                       stop_words='english'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# use CountVectorizer to vectorize the training data\n",
    "X_train_cvec= cvec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logisticRegression model with lasso\n",
    "lr = LogisticRegression('l1')\n",
    "lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X_train_cvec as a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "cvec_words = pd.DataFrame(X_train_cvec.toarray(), columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add word counts to the dataframe\n",
    "cv_table_lr = pd.DataFrame(cvec_words.sum(), index = cvec.get_feature_names(), columns=['word_count'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coefficient to the table\n",
    "import numpy as np\n",
    "\n",
    "cv_table_lr['coef'] = lr.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index and change column names\n",
    "cv_table_lr = cv_table_lr.reset_index()\n",
    "cv_table_lr = cv_table_lr.rename({'index': 'word'}, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>spacex</td>\n",
       "      <td>361</td>\n",
       "      <td>4.094957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>starlink</td>\n",
       "      <td>61</td>\n",
       "      <td>3.592743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>dragon</td>\n",
       "      <td>87</td>\n",
       "      <td>3.503942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>starship</td>\n",
       "      <td>85</td>\n",
       "      <td>3.417269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>stp</td>\n",
       "      <td>21</td>\n",
       "      <td>3.397308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>falcon</td>\n",
       "      <td>155</td>\n",
       "      <td>3.361128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>raptor</td>\n",
       "      <td>30</td>\n",
       "      <td>2.915407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>elon</td>\n",
       "      <td>71</td>\n",
       "      <td>2.507829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>press</td>\n",
       "      <td>16</td>\n",
       "      <td>2.235897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>station</td>\n",
       "      <td>19</td>\n",
       "      <td>2.188803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  word_count      coef\n",
       "834    spacex         361  4.094957\n",
       "863  starlink          61  3.592743\n",
       "263    dragon          87  3.503942\n",
       "866  starship          85  3.417269\n",
       "880       stp          21  3.397308\n",
       "318    falcon         155  3.361128\n",
       "712    raptor          30  2.915407\n",
       "278      elon          71  2.507829\n",
       "677     press          16  2.235897\n",
       "874   station          19  2.188803"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table_lr.sort_values(by='coef', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>blue</td>\n",
       "      <td>333</td>\n",
       "      <td>-3.918094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>blueorigin</td>\n",
       "      <td>38</td>\n",
       "      <td>-3.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>glenn</td>\n",
       "      <td>79</td>\n",
       "      <td>-2.462943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bezos</td>\n",
       "      <td>102</td>\n",
       "      <td>-2.251055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>shepard</td>\n",
       "      <td>100</td>\n",
       "      <td>-1.894246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>bo</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.613705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>-1.477089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>jeff</td>\n",
       "      <td>89</td>\n",
       "      <td>-1.403821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>provider</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.367819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>new</td>\n",
       "      <td>295</td>\n",
       "      <td>-1.351854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  word_count      coef\n",
       "108        blue         333 -3.918094\n",
       "111  blueorigin          38 -3.032898\n",
       "361       glenn          79 -2.462943\n",
       "97        bezos         102 -2.251055\n",
       "784     shepard         100 -1.894246\n",
       "113          bo           9 -1.613705\n",
       "56       amazon          17 -1.477089\n",
       "437        jeff          89 -1.403821\n",
       "695    provider           3 -1.367819\n",
       "580         new         295 -1.351854"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_table_lr.sort_values(by='coef', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'cv_table_lr' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# store cv_table for data visualization\n",
    "%store cv_table_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
